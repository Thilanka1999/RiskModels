{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role ARN: arn:aws:iam::796932308591:role/service-role/SageMaker-ExecutionRole-20250214T145019\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"SageMaker Role ARN: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket = 'mitrailabs-personaclassification'\n",
    "model_prefix = 'risk_prediction/data/'\n",
    "response = s3.get_object(\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{model_prefix}feature_engineered_data.csv\"\n",
    ")\n",
    "\n",
    "X_processed = pd.read_csv(response['Body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X_processed.columns\n",
    "# numerical_pipeline = Pipeline([\n",
    "#     ('scaler', MinMaxScaler())\n",
    "# ])\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_pipeline, numerical_cols),\n",
    "#         # ('cat', categorical_pipeline, categorical_cols)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# X_scaled = preprocessor.fit_transform(X_processed)\n",
    "# X_processed = pd.DataFrame(\n",
    "#     X_scaled, \n",
    "#     columns=numerical_cols#+categorical_cols#[name.split('__')[-1] for name in preprocessor.get_feature_names_out()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X_processed.columns\n",
    "X_scaled = X_processed.copy() \n",
    "X_scaled = StandardScaler().fit_transform(X_scaled)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         # ('num', numerical_pipeline, numerical_cols),\n",
    "#         ('cat', numerical_pipeline, [i for i in numerical_cols if i != \"target_default\"])\n",
    "#     ],\n",
    "#     # remainder='drop'  # <--- IMPORTANT: Drop the remaining columns\n",
    "# )\n",
    "\n",
    "# inference_preprocessor.fit(X_processed_copy.drop(columns=[\"target_default\"]))\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# # For the second save (which appears duplicative but keeping structure)\n",
    "# inference_preprocessor_path = 'saved/inference_preprocessor.joblib'\n",
    "# joblib.dump(inference_preprocessor, inference_preprocessor_path)\n",
    "\n",
    "# # Upload to S3 (updating file extension)\n",
    "# target_bucket = 'mitrailabs-personaclassification'\n",
    "# target_prefix = 'risk_prediction/Intermediate_states'\n",
    "# model_path = f'{target_prefix}/inference_preprocessor.joblib'\n",
    "# s3.upload_file(\n",
    "#     inference_preprocessor_path,\n",
    "#     target_bucket,\n",
    "#     model_path\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements2.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1573\n",
      "1     5029\n",
      "2    12387\n",
      "3    11069\n",
      "4    11288\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Perform K-Means clustering on normalized data\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the original dataset\n",
    "X_processed['Cluster'] = clusters\n",
    "\n",
    "print(pd.Series(clusters).value_counts().sort_index())\n",
    "# Display the clustered data\n",
    "(X_processed.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_processed_path = 'saved/clustered_data.csv'\n",
    "X_processed.to_csv(X_processed_path, index=False)\n",
    "\n",
    "target_bucket = 'mitrailabs-personaclassification'\n",
    "target_prefix = 'risk_prediction/data'\n",
    "\n",
    "\n",
    "model_path = f'{target_prefix}/clustered_data.csv'\n",
    "s3.upload_file(X_processed_path, \n",
    "               target_bucket, \n",
    "               model_path\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target_default', 'score_1', 'score_3', 'score_4', 'score_5', 'score_6',\n",
       "       'risk_rate', 'last_amount_borrowed', 'last_borrowed_in_months',\n",
       "       'credit_limit', 'income', 'facebook_profile', 'state', 'real_state',\n",
       "       'ok_since', 'n_accounts', 'n_issues', 'application_time_in_funnel',\n",
       "       'external_data_provider_credit_checks_last_month',\n",
       "       'external_data_provider_credit_checks_last_year',\n",
       "       'external_data_provider_email_seen_before',\n",
       "       'external_data_provider_fraud_score', 'reported_income',\n",
       "       'shipping_state', 'last_amount_borrowed_log',\n",
       "       'last_borrowed_in_months_log', 'credit_limit_log', 'income_log',\n",
       "       'ok_since_log', 'n_accounts_log', 'n_issues_log', 'reported_income_log',\n",
       "       'credit_utilization', 'reported_income_div_income',\n",
       "       'facebook_profile_times_income', 'credit_available',\n",
       "       'income_per_account', 'loan_amount_to_income',\n",
       "       'n_accounts_to_credit_limit', 'credit_utilization_x_fraud_score',\n",
       "       'real_state_avg_facebook_profile',\n",
       "       'shipping_state_avg_facebook_profile', 'state_x_real_state',\n",
       "       'state_x_shipping_state', 'state_real_state_avg_score_1', 'Cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
