{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import inference_validator, reasoning, feature_engineering, additional_feature_engineering\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)  # None means unlimited rows\n",
    "pd.set_option('display.max_columns', None) # None means unlimited columns\n",
    "pd.set_option('display.width', None)      # None means auto-detect width\n",
    "pd.set_option('display.max_colwidth', None) # None means unlimited column width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, json\n",
    "with open('saved/nimputer.pkl', 'rb') as f:\n",
    "    nimputer = pickle.load(f)\n",
    "\n",
    "with open('saved/cimputer.pkl', 'rb') as f:\n",
    "    cimputer = pickle.load(f)\n",
    "\n",
    "with open('saved/label_encoders.pkl', 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "\n",
    "    \n",
    "with open('saved/inference_preprocessor.pkl', 'rb') as f:\n",
    "    inference_preprocessor = pickle.load(f)\n",
    "\n",
    "with open('saved/xgb_model.pkl', 'rb') as f:\n",
    "    xgb = pickle.load(f)\n",
    "\n",
    "with open('saved/before_feature.json', 'r') as f:\n",
    "    before_columns = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Example user input\n",
    "user_input = {\n",
    "    'score_3': 0.5, 'score_4': np.nan, 'score_5': 0.7, 'score_6': np.nan,\n",
    "    'risk_rate': 0.2, 'last_amount_borrowed': 1000, 'last_borrowed_in_months': 12,\n",
    "    'credit_limit': 5000, 'income': np.nan, 'ok_since': 24, 'n_bankruptcies': 9,\n",
    "    'n_defaulted_loans': 1, 'n_accounts': 3, 'n_issues': 2,\n",
    "    'external_data_provider_credit_checks_last_year': 3,\n",
    "    'external_data_provider_email_seen_before': 1, 'reported_income': 50000,\n",
    "    'application_time_in_funnel': 5, 'external_data_provider_credit_checks_last_month': 0,\n",
    "    'external_data_provider_fraud_score': 50, 'shipping_state': np.nan,\n",
    "    'facebook_profile': True, 'state': np.nan, 'score_1': np.nan, 'score_2': np.nan, \"real_state\":'a'\n",
    "}\n",
    "\n",
    "# user_input = {\n",
    "#     'score_3': 510, 'score_4': np.nan, 'score_5': 0.480, 'score_6': 92,\n",
    "#     'risk_rate': 0.45, 'last_amount_borrowed': 600, 'last_borrowed_in_months': 20,\n",
    "#     'credit_limit': 500, 'income': 60000, 'ok_since': 32, 'n_bankruptcies': 3.0,\n",
    "#     'n_defaulted_loans': 0, 'n_accounts': 25.0, 'n_issues': 5.0,\n",
    "#     'external_data_provider_credit_checks_last_year': 4.0,\n",
    "#     'external_data_provider_email_seen_before': 5, 'reported_income': 50000,\n",
    "#     'application_time_in_funnel': 900, 'external_data_provider_credit_checks_last_month': 5.0,\n",
    "#     'external_data_provider_fraud_score': 250, 'shipping_state': np.nan,\n",
    "#     'facebook_profile': True, 'state': np.nan, 'score_1': '1Rk8w4Ucd5yR3KcqZzLdow==', 'score_2': np.nan, \"real_state\": np.nan\n",
    "# }\n",
    "\n",
    "user_input = {\n",
    "    \"score_3\": 500,                     # Min: 0, Max: 990\n",
    "    \"score_4\": 80,                    # Min: 86.191572, Max: 113.978234\n",
    "    \"score_5\": 0.5,                    # Min: 0.000035, Max: 0.999973\n",
    "    \"score_6\": 100,                      # Min: 60.663039, Max: 142.192400\n",
    "    \"risk_rate\": 0.6,                  # Min: 0.000000, Max: 0.900000\n",
    "    \"last_amount_borrowed\": 10000000,        # Min: 0.000000, Max: 35059.600000\n",
    "    \"last_borrowed_in_months\": 1,      # Min: 0.000000, Max: 60.000000\n",
    "    \"credit_limit\": 100000,                 # Min: 0.000000, Max: 448269.000000\n",
    "    \"income\": 1200000,                   # Min: 4821.180000, Max: 5000028.000000\n",
    "    \"ok_since\": 1,                     # Min: 0.000000, Max: 141.000000\n",
    "    \"n_accounts\": 1,                 # Min: 0.000000, Max: 49.000000\n",
    "    \"n_issues\": 0,                    # Min: 0.000000, Max: 49.000000\n",
    "    \"external_data_provider_credit_checks_last_year\": 1, # Min: 0.000000, Max: 1.000000\n",
    "    \"external_data_provider_email_seen_before\": 50,        # Min: 0.000000, Max: 59.000000\n",
    "    \"reported_income\": 120000,          # Min: 403.000000, Max: 6355500000000000.000000\n",
    "    \"application_time_in_funnel\": 300,  # Min: 0.000000, Max: 500.000000\n",
    "    \"external_data_provider_credit_checks_last_month\": 0.0, # Min: 0.000000, Max: 3.000000\n",
    "    \"external_data_provider_fraud_score\": 0, # Min: 0.000000, Max: 1000.000000\n",
    "    \"shipping_state\": np.nan,             # No min/max provided (categorical)\n",
    "    \"facebook_profile\": False,          # No min/max provided (boolean)\n",
    "    \"state\": \"BR-MS\",                      # No min/max provided (categorical)\n",
    "    \"score_1\": \"1Rk8w4Ucd5yR3KcqZzLdow==\", # No min/max provided (encoded string)\n",
    "    \"real_state\": np.nan                  # No min/max provided (nullnp.nan\n",
    "}\n",
    "user_input = inference_validator(user_input)\n",
    "\n",
    "user_df = pd.DataFrame([user_input])\n",
    "\n",
    "# Ensure the user input has the same columns as the training data\n",
    "user_df = user_df.reindex(columns=before_columns, fill_value=np.nan)\n",
    "\n",
    "# Assuming you know which features each imputer was trained on\n",
    "c_features = [f for f in cimputer.feature_names_in_ if f in user_df.columns]\n",
    "n_features = [f for f in nimputer.feature_names_in_ if f in user_df.columns]\n",
    "\n",
    "\n",
    "# Apply only if features exist\n",
    "if c_features:\n",
    "    user_df[c_features] = cimputer.transform(user_df[c_features])\n",
    "if n_features:\n",
    "    user_df[n_features] = nimputer.transform(user_df[n_features])\n",
    "\n",
    "user_df = user_df.drop(columns=[\"target_default\"])\n",
    "# print(\"target_default\" in user_df.columns)\n",
    "\n",
    "# Apply the same label encoding to the user input\n",
    "# for col in c_features:\n",
    "#     if col in user_df.columns and col != \"target_default\":\n",
    "#         # Use the transform method of the fitted LabelEncoder\n",
    "#         user_df[col] = label_encoders[col].transform(user_df[col])\n",
    "user_df[[i for i in c_features if i != \"target_default\"]] = label_encoders.transform(user_df[[i for i in c_features if i != \"target_default\"]])\n",
    "\n",
    "# yo_features = [i for i in c_features + n_features if i != \"target_default\"]\n",
    "# user_df = user_df.reindex(columns=yo_features)\n",
    "\n",
    "user_df = feature_engineering(user_df)\n",
    "user_df = additional_feature_engineering(user_df)\n",
    "# print(user_df)\n",
    "# user_processed = inference_preprocessor.transform(user_df)\n",
    "\n",
    "\n",
    "# Make prediction\n",
    "prediction = xgb.predict(user_df)\n",
    "prediction_proba = xgb.predict_proba(user_df)\n",
    "\n",
    "print(\"Prediction:\", prediction)\n",
    "print(reasoning[str(prediction[0])])\n",
    "print(\"Prediction Probability:\", prediction_proba)\n",
    "# print(user_processed)\n",
    "# 6 → 3 → 7 → 1 → 2 → 0 → 5 → 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
