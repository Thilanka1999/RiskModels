{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import inference_validator, reasoning, feature_engineering\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)  # None means unlimited rows\n",
    "pd.set_option('display.max_columns', None) # None means unlimited columns\n",
    "pd.set_option('display.width', None)      # None means auto-detect width\n",
    "pd.set_option('display.max_colwidth', None) # None means unlimited column width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, json\n",
    "with open('saved/nimputer.pkl', 'rb') as f:\n",
    "    nimputer = pickle.load(f)\n",
    "\n",
    "with open('saved/cimputer.pkl', 'rb') as f:\n",
    "    cimputer = pickle.load(f)\n",
    "\n",
    "with open('saved/xgb_model.pkl', 'rb') as f:\n",
    "    xgb = pickle.load(f)\n",
    "\n",
    "with open('saved/before_feature.json', 'r') as f:\n",
    "    before_columns = json.load(f)\n",
    "\n",
    "with open('saved/df_train_encoded.json', 'r') as f:\n",
    "    df_train_encoded = json.load(f)\n",
    "    \n",
    "with open('saved/encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# List of categorical columns\n",
    "c_columns = ['HighDebtToIncome', 'AgeBin', 'CreditScoreBin', 'EmploymentStatus', \n",
    "             'MaritalStatus', 'HomeOwnershipStatus', 'EducationLevel', 'LoanPurpose']\n",
    "\n",
    "# Get feature names from the encoder\n",
    "feature_names = encoder.get_feature_names_out(c_columns)\n",
    "\n",
    "# During training\n",
    "def transform_with_encoder(X, categorical_cols, other_cols, encoder):\n",
    "    # Apply encoding to categorical columns\n",
    "    encoded_array = encoder.transform(X[categorical_cols])\n",
    "    \n",
    "    # Convert to DataFrame with proper column names\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_array, \n",
    "        columns=encoder.get_feature_names_out(categorical_cols),\n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    # Combine with non-categorical columns\n",
    "    if other_cols:\n",
    "        result = pd.concat([X[other_cols], encoded_df], axis=1)\n",
    "    else:\n",
    "        result = encoded_df\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groq_api_key = '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'\n",
    "import groq\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Client(api_key=\"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\")\n",
    "\n",
    "def get_risk_category_reasoning(user_df, prediction, prediction_proba):\n",
    "    # Convert the user_df to a readable format for the LLM\n",
    "    user_data_str = user_df.to_string()\n",
    "\n",
    "    # Prepare the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"You are a financial risk analyst. A user has applied for a loan, and the machine learning model has predicted their risk category as {prediction[0]} (0-4, where 0 is the lowest risk and 4 is the highest).\\n\\n\"\n",
    "        f\"The prediction probabilities are: {prediction_proba[0]}.\\n\\n\"\n",
    "        f\"Below are the user's details after feature engineering:\\n\"\n",
    "        f\"{user_data_str}\\n\\n\"\n",
    "        f\"### Instructions:\\n\"\n",
    "        f\"- Provide a detailed explanation of why this person belongs to the predicted risk category.\\n\"\n",
    "        f\"- Highlight key features that contributed to the risk level (e.g., high debt-to-income ratio, low credit score, etc.).\\n\"\n",
    "        f\"- Explain how these features align with the risk category.\\n\"\n",
    "        f\"- Mention any mitigating factors that could lower the risk or exacerbate it.\\n\"\n",
    "        f\"- Provide recommendations for the user to improve their risk profile if applicable.\\n\\n\"\n",
    "        f\"### Output Format:\\n\"\n",
    "        f\"- Output ONLY a plain text explanation without any additional formatting or labels.\\n\"\n",
    "    )\n",
    "\n",
    "    # Call the Groq API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.2-3b-preview\",  # Replace with the actual Groq model name\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial risk analyst. Provide a detailed explanation of the user's risk category based on their data.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    # Extract and return the reasoning\n",
    "    reasoning = response.choices[0].message.content.strip()\n",
    "    return reasoning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "user_input = {\n",
    "  \"ApplicationDate\": \"2024-03-02\",\n",
    "  \"Age\": 52,\n",
    "  \"AnnualIncome\": 9500000,\n",
    "  \"CreditScore\": 820,\n",
    "  \"EmploymentStatus\": \"Employed\",\n",
    "  \"EducationLevel\": \"Master\",\n",
    "  \"Experience\": 28,\n",
    "  \"LoanAmount\": 15000,\n",
    "  \"LoanDuration\": 36,\n",
    "  \"MaritalStatus\": \"Married\",\n",
    "  \"NumberOfDependents\": 2,\n",
    "  \"HomeOwnershipStatus\": \"Own\",\n",
    "  \"MonthlyDebtPayments\": 900,\n",
    "  \"CreditCardUtilizationRate\": 0.12,\n",
    "  \"NumberOfOpenCreditLines\": 3,\n",
    "  \"NumberOfCreditInquiries\": 0,\n",
    "  \"DebtToIncomeRatio\": 0.15,\n",
    "  \"BankruptcyHistory\": 0,\n",
    "  \"LoanPurpose\": \"Home\",\n",
    "  \"PreviousLoanDefaults\": 0,\n",
    "  \"PaymentHistory\": 36,\n",
    "  \"LengthOfCreditHistory\": 20,\n",
    "  \"SavingsAccountBalance\": 30000,\n",
    "  \"CheckingAccountBalance\": 20000,\n",
    "  \"TotalAssets\": 300000,\n",
    "  \"TotalLiabilities\": 25000,\n",
    "  \"MonthlyIncome\": 130000,\n",
    "  \"UtilityBillsPaymentHistory\": 0.98,\n",
    "  \"JobTenure\": 15,\n",
    "  \"NetWorth\": 275000,\n",
    "  \"BaseInterestRate\": 3.5,\n",
    "  \"InterestRate\": 4.5,\n",
    "  \"MonthlyLoanPayment\": 500,\n",
    "  \"TotalDebtToIncomeRatio\": 0.2\n",
    "}\n",
    "user_input = inference_validator(user_input)\n",
    "user_df = pd.DataFrame([user_input])\n",
    "\n",
    "if isinstance(user_df, pd.Series):\n",
    "    user_df = user_df.to_frame().T\n",
    "\n",
    "# Ensure the user input has the same columns as the training data\n",
    "user_df = user_df.reindex(columns=before_columns, fill_value=np.nan)\n",
    "\n",
    "# Assuming you know which features each imputer was trained on\n",
    "c_features = [f for f in cimputer.feature_names_in_ if f in user_df.columns]\n",
    "n_features = [f for f in nimputer.feature_names_in_ if f in user_df.columns]\n",
    "\n",
    "\n",
    "# Apply only if features exist\n",
    "if c_features:\n",
    "    user_df[c_features] = cimputer.transform(user_df[c_features])\n",
    "if n_features:\n",
    "    user_df[n_features] = nimputer.transform(user_df[n_features])\n",
    "\n",
    "\n",
    "user_df = feature_engineering(user_df)\n",
    "\n",
    "# Get non-categorical columns\n",
    "other_columns = [col for col in user_df.columns if col not in c_columns]\n",
    "\n",
    "# print(user_df.columns)\n",
    "# print(c_columns)\n",
    "# print(other_columns) #'AgeBin_30-40', 'AgeBin_40-50', 'AgeBin_50-60', 'AgeBin_60+', 'CreditScoreBin_Fair', 'CreditScoreBin_Good', 'CreditScoreBin_Excellent']\n",
    "# Apply the transformation\n",
    "\n",
    "user_df = transform_with_encoder(user_df, c_columns, other_columns, encoder)\n",
    "# user_df = user_df.reindex(columns=df_train_encoded, fill_value=0)\n",
    "user_df = user_df.drop(columns=['LoanApproved', \"RiskScore\"])\n",
    "\n",
    "# print(user_df.columns)\n",
    "# user_df = user_df.reindex(columns=xgb.get_booster().feature_names, fill_value=0)\n",
    "\n",
    "prediction = xgb.predict(user_df)\n",
    "prediction_proba = xgb.predict_proba(user_df)\n",
    "\n",
    "print(\"Prediction:\", prediction)\n",
    "reasoning = get_risk_category_reasoning(user_df, prediction, prediction_proba)\n",
    "print(\"Reasoning for Risk Category:\", reasoning)\n",
    "print(\"Prediction Probability:\", prediction_proba)\n",
    "# print(user_processed)\n",
    "# 6 → 3 → 7 → 1 → 2 → 0 → 5 → 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
