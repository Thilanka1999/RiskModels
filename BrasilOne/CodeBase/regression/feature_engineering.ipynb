{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from utils import feature_engineering\n",
    "# set the aesthetic style of the plots\n",
    "sns.set_style()\n",
    "pd.set_option('display.max_rows', None)  # None means unlimited rows\n",
    "pd.set_option('display.max_columns', None) # None means unlimited columns\n",
    "pd.set_option('display.width', None)      # None means auto-detect width\n",
    "pd.set_option('display.max_colwidth', None) # N\n",
    "# filter warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv('saved/preprocessed_bank_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = feature_engineering(df_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_credit_correlation\n",
    "\n",
    "# Example usage:\n",
    "ordinal_cols = ['EmploymentStatus', 'EducationLevel']\n",
    "target_cols = ['MaritalStatus', 'LoanPurpose', 'HomeOwnershipStatus']\n",
    "# plot_credit_correlation(df_credit, ordinal_cols, target_cols, 'RiskScore')\n",
    "plot_credit_correlation(df_credit, ordinal_cols, target_cols, 'RiskScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# List of categorical columns\n",
    "c_columns = ['EmploymentStatus', \n",
    "             'MaritalStatus', 'HomeOwnershipStatus', 'EducationLevel', 'LoanPurpose']\n",
    "\n",
    "# Create and fit the encoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "encoder.fit(X_processed[c_columns])\n",
    "\n",
    "# Get feature names from the encoder\n",
    "feature_names = encoder.get_feature_names_out(c_columns)\n",
    "# During training\n",
    "def transform_with_encoder(X, categorical_cols, other_cols, encoder):\n",
    "    # Apply encoding to categorical columns\n",
    "    encoded_array = encoder.transform(X[categorical_cols])\n",
    "    \n",
    "    # Convert to DataFrame with proper column names\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_array, \n",
    "        columns=encoder.get_feature_names_out(categorical_cols),\n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    # Combine with non-categorical columns\n",
    "    if other_cols:\n",
    "        result = pd.concat([X[other_cols], encoded_df], axis=1)\n",
    "    else:\n",
    "        result = encoded_df\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Get non-categorical columns\n",
    "other_columns = [col for col in X_processed.columns if col not in c_columns]\n",
    "print(X_processed.columns)\n",
    "print(c_columns)\n",
    "print(other_columns)\n",
    "\n",
    "# Apply the transformation\n",
    "X_processed = transform_with_encoder(X_processed, c_columns, other_columns, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save label encoders to disk\n",
    "with open('saved/encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "print(X_processed.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_processed.applymap(lambda x: x if x > 0 else np.nan)\n",
    "\n",
    "# Take the log of each feature\n",
    "df_log = df.applymap(np.log1p)\n",
    "\n",
    "# Calculate correlation between original and log-transformed features\n",
    "correlation_results = {}\n",
    "for col in df.columns:\n",
    "    correlation = df[col].corr(df_log[col])\n",
    "    correlation_results[col] = correlation\n",
    "\n",
    "# Rank the correlations from highest to lowest\n",
    "ranked_correlations = pd.Series(correlation_results).sort_values(ascending=False)\n",
    "\n",
    "# Display the results\n",
    "# print(\"Correlation between original and log-transformed features:\")\n",
    "# print(ranked_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_processed[X_processed['RiskScore'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed.to_csv('saved/feature_engineered_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
