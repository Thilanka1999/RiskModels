{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, TargetEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from utils import feature_engineering, additional_feature_engineering\n",
    "# set the aesthetic style of the plots\n",
    "sns.set_style()\n",
    "\n",
    "# filter warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv('saved/preprocessed_bank_data.csv')\n",
    "df_credit.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = feature_engineering(df_credit)\n",
    "X_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_processed[X_processed['target_default'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed.nunique().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ManualTargetEncoder:\n",
    "    def __init__(self, smoothing=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the encoder.\n",
    "        :param smoothing: Smoothing parameter to balance between category mean and global mean.\n",
    "        \"\"\"\n",
    "        self.smoothing = smoothing\n",
    "        self.encodings = {}  # Store encodings for each categorical column\n",
    "        self.global_mean = None  # Store the global mean of the target\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the encoder on the training data.\n",
    "        :param X: DataFrame containing categorical columns.\n",
    "        :param y: Target variable.\n",
    "        \"\"\"\n",
    "        self.global_mean = y.mean()\n",
    "\n",
    "        for col in X.columns:\n",
    "            # Calculate the mean target for each category\n",
    "            category_means = y.groupby(X[col]).mean()\n",
    "            # Calculate the count of each category\n",
    "            category_counts = y.groupby(X[col]).count()\n",
    "            # Apply smoothing\n",
    "            smoothed_encoding = (category_means * category_counts + self.global_mean * self.smoothing) / (\n",
    "                        category_counts + self.smoothing)\n",
    "            # Store the encodings\n",
    "            self.encodings[col] = smoothed_encoding\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform the categorical columns using the learned encodings.\n",
    "        :param X: DataFrame containing categorical columns.\n",
    "        :return: Transformed DataFrame.\n",
    "        \"\"\"\n",
    "        X_transformed = X.copy()\n",
    "        for col in X.columns:\n",
    "            # Replace categories with their encodings\n",
    "            X_transformed[col] = X[col].map(self.encodings[col]).fillna(self.global_mean)\n",
    "        return X_transformed\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the encoder and transform the data in one step.\n",
    "        :param X: DataFrame containing categorical columns.\n",
    "        :param y: Target variable.\n",
    "        :return: Transformed DataFrame.\n",
    "        \"\"\"\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import category_encoders as ce\n",
    "X_processed[\"target_default\"] = X_processed[\"target_default\"].astype(int)\n",
    "\n",
    "X = X_processed.drop(columns=[\"target_default\"])\n",
    "y = X_processed[\"target_default\"]\n",
    "\n",
    "categorical_cols = X.select_dtypes(exclude=['float64', 'int64']).columns.tolist()\n",
    "# print(categorical_cols)\n",
    "# # Check for missing values in each categorical column\n",
    "# nan_counts = X_processed[categorical_cols].isnull().sum()\n",
    "\n",
    "# # Print the columns with NaNs and their counts\n",
    "# print(nan_counts[nan_counts > 0])\n",
    "# Define the one-out encoder\n",
    "encoder = ManualTargetEncoder(smoothing=1.0)\n",
    "X_processed[categorical_cols] = encoder.fit_transform(X[categorical_cols], y)\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # None means unlimited rows\n",
    "pd.set_option('display.max_columns', None) # None means unlimited columns\n",
    "pd.set_option('display.width', None)      # None means auto-detect width\n",
    "pd.set_option('display.max_colwidth', None) # None means unlimited column width\n",
    "print(X.head(10))\n",
    "\n",
    "# Save label encoders to disk\n",
    "with open('saved/label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed.nunique().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric = X_processed[['state', 'real_state']].applymap(lambda x: isinstance(x, str)).sum()\n",
    "print(non_numeric[non_numeric > 0])  # Show columns that still have categorical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed2 = additional_feature_engineering(X_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# # Separate features (X) and target (y)\n",
    "# X = df_credit.drop('target_default', axis=1)\n",
    "# y = df_credit['target_default']\n",
    "\n",
    "# # Apply SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# # Create a new DataFrame with resampled data\n",
    "# df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "# df_resampled['target_default'] = y_resampled\n",
    "\n",
    "# Save the resampled data to a new CSV file\n",
    "# df_resampled.to_csv('saved/feature_engineered_data.csv', index=False)\n",
    "\n",
    "# print(\"SMOTE applied and saved to 'saved/feature_engineered_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.to_csv('saved/feature_engineered_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
